{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just plain boring</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entirely predictable and lacks energy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no surprises and very few laughs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very powerful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the most fun film of the summer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                document  class\n",
       "0                      just plain boring      0\n",
       "1  entirely predictable and lacks energy      0\n",
       "2       no surprises and very few laughs      0\n",
       "3                          very powerful      1\n",
       "4        the most fun film of the summer      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['just plain boring', 'entirely predictable and lacks energy',\n",
       "        'no surprises and very few laughs', 'very powerful',\n",
       "        'the most fun film of the summer'], dtype=object),\n",
       " array([0, 0, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data['document'].values\n",
    "y_train = train_data['class'].values\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 0\n",
      "prob: 0.000711111111111111\n",
      "class: 1\n",
      "prob: 0.0008\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.voc = set() # vocabulary in X_train\n",
    "\n",
    "\n",
    "    def tokenize(self, unk=True):\n",
    "        # eliminate symbols on input text\n",
    "        sims = \"!\\\"#$%&()*+-.,'/:;<=>?@[\\]^_`{|}~\\n\"\n",
    "        for si in sims:\n",
    "            text = text.replace(si, '')\n",
    "\n",
    "        # lower text\n",
    "        text = text.lower()\n",
    "\n",
    "        # separate text by words\n",
    "        words = text.split(' ')\n",
    "\n",
    "        # add words to vocabulary\n",
    "        if unk:\n",
    "            for wi in words:\n",
    "                if wi not in self.voc:\n",
    "                    self.voc.add(wi)\n",
    "        else:\n",
    "            aux = [] # only add words in vocabulary\n",
    "            for wi in words:\n",
    "                if wi in self.voc:\n",
    "                    aux.append(wi)\n",
    "            words = aux\n",
    "\n",
    "        return words\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # identify unique classes and calculate prior probabilities p(c) for each class\n",
    "        self.clases, counts = np.unique(y_train, return_counts=True)\n",
    "        self.Pcs = [ci/len(X_train) for ci in counts]\n",
    "        #print(f'Pcs: {self.Pcs}')\n",
    "\n",
    "        # calculate bag of words per class\n",
    "        self.bags = []\n",
    "        self.bags_len = []\n",
    "        for i, ci in enumerate(self.clases):\n",
    "            #print(f'class: {ci}')\n",
    "            \n",
    "            # documents of each class\n",
    "            docs = X_train[y_train==ci]\n",
    "            #print(docs)\n",
    "\n",
    "            # concatenate docs and identify unique words and count\n",
    "            concat = []\n",
    "            for di in docs:\n",
    "                concat += self.tokenize(di)\n",
    "            \n",
    "            self.bags_len.append(len(concat)) # bag len\n",
    "\n",
    "            ks, vs = np.unique(concat, return_counts=True)\n",
    "            auxd = {}\n",
    "            for j in range(len(ks)):\n",
    "                auxd[ks[j]] = vs[j]\n",
    "            self.bags.append(auxd) # add bag of words\n",
    "            #print(f'bag: {auxd}')\n",
    "        #print(f'bags: {self.bags}\\n len: {self.bags_len}')\n",
    "    \n",
    "\n",
    "    def count(self, w, ci):\n",
    "        if w in self.bags[ci]: # if w is in ci bag of words\n",
    "            return self.bags[ci][w]\n",
    "        else: # if w not in the ci bag of words, return 0\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        preds = []\n",
    "\n",
    "        for xi in X_test:\n",
    "            auxp = []\n",
    "            for ci, cl in enumerate(self.clases):\n",
    "                print(f'class: {cl}')\n",
    "                # class probability\n",
    "                priorc = self.Pcs[ci]\n",
    "\n",
    "                # likelohood probability\n",
    "                lp = 1\n",
    "                for wi in self.tokenize(xi, unk=False):\n",
    "                    lp = lp * (self.count(wi, ci) + 1) / (self.bags_len[ci] + 1)\n",
    "                probc = priorc*lp # probability of xi belonginf to class c\n",
    "                auxp.append(probc)\n",
    "                print(f'prob: {probc}')\n",
    "        \n",
    "            \n",
    "    def tokenize(self, text, unk=True):\n",
    "        # eliminate symbols on input text\n",
    "        sims = \"!\\\"#$%&()*+-.,'/:;<=>?@[\\]^_`{|}~\\n\"\n",
    "        for si in sims:\n",
    "            text = text.replace(si, '')\n",
    "\n",
    "        # lower text\n",
    "        text = text.lower()\n",
    "\n",
    "        # separate text by words\n",
    "        words = text.split(' ')\n",
    "\n",
    "        # add words to vocabulary\n",
    "        if unk:\n",
    "            for wi in words:\n",
    "                if wi not in self.voc:\n",
    "                    self.voc.add(wi)\n",
    "        else:\n",
    "            aux = [] # only add words in vocabulary\n",
    "            for wi in words:\n",
    "                if wi in self.voc:\n",
    "                    aux.append(wi)\n",
    "            words = aux\n",
    "\n",
    "        return words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test = NaiveBayes()\n",
    "test.fit(X_train, y_train)\n",
    "test.predict(['predictable with no fun'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
